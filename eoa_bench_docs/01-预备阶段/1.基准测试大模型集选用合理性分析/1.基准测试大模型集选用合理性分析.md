# 1.基准测试大模型集选用合理性分析

## 一、分析对象
### 1.1 问题背景
在端侧AI推理优化基准测试项目中，大模型集的选用是基础性且关键性的决策。MNN框架目前官方支持150+个模型，涵盖文本、视觉、语音等多种模态，**多模态模型成为主流趋势**。如何从丰富的大模型生态中选择具有代表性的子集，建立全面的基准测试体系，既体现技术发展趋势又满足实际应用需求，是本项目面临的重要任务。

### 1.2 核心问题
**MNN大模型生态分析：**
- MNN官方支持150+个模型
- **选择范围广泛**：包含文本、视觉、语音等多种处理能力的大模型
- 端侧部署的实际需求需要考虑模型规模和设备适配性

**综合选择策略：**
- 纳入多模态模型，覆盖更广泛的大模型应用场景
- 在不大于10个模型的约束下实现架构、规模、应用的最大覆盖度
- 平衡测试的可行性与代表性，确保基准测试的实用价值

### 1.3 分析范围与边界
- **核心验证：** 建立大模型选择的科学体系和代表性覆盖策略
- **测试环境：** MNN推理引擎，FT D3000处理器（8核），32GB内存
- **评估维度：** 大模型架构多样性、参数规模分布、多模态应用场景覆盖度
- **分析方法：** 维度分析+覆盖度优化算法
- **包含范围：** 纯文本LLM模型、多模态模型、专业领域模型等所有大模型类型
- **约束条件：** 模型参数主要<10B，最终选择10个以下代表性模型，适配端侧部署实际需求
- **备注：** 硬件和软件环境待细化为真实场景数据

## 二、论证方法
### 2.1 总体论证思路
**基于大模型生态系统，通过全面的维度体系设计，采用覆盖度优化算法，在10个模型约束下实现文本、视觉、语音等多领域大模型特性的全面覆盖**

### 2.2 选择维度体系
**核心维度设计：**

#### 2.2.1 处理模态维度（第一分类维度）
- **纯文本模型：** 专门处理文本内容的模型（Qwen2.5、Meta-Llama-3.1、Hunyuan、Gemma-2等）
- **多模态模型：** 支持文本+视觉联合处理的模型（Qwen-VL、Gemma-3、MiniCPM-V、InternVL2等）
- **语音处理模型：** 专门处理语音内容的模型（bert-vits2、piper-voices、sherpa-mnn等）
- **跨模态统一模型：** 【未来趋势，当前在MNN中较少见】

#### 2.2.2 参数规模维度（第二分类维度）
- **微型级：** < 1B参数，适合高效轻量部署
- **小型级：** 1B-2B参数，移动端主力区间
- **中型级：** 3B-8B参数，边缘计算主流区间
- **大型级：** 8B-10B参数，高性能端侧设备
- **超大规模级：** 30B+总参数（MoE架构，Active参数3-4B）

#### 2.2.3 厂商生态维度（第三分类维度）
- **通义千问生态**：Qwen系列（文本、VL、Coder、Math、Thinking、Embedding、Guard等）
- **Meta生态**：Meta-Llama系列、Llama系列
- **Google生态**：Gemma系列
- **国产厂商生态**：腾讯混元、DeepSeek、MiniCPM、InternVL、智谱AI等
- **开源社区生态**：SmolLM、MobileLLM等

#### 2.2.4 应用功能维度（第四分类维度）
- **通用对话**：日常对话、问答、文本生成
- **代码开发**：代码生成、理解、补全
- **数学推理**：数学求解、逻辑推理
- **视觉理解**：图像理解、图文对话、文档解析
- **专业领域**：医疗、法律、安全审核等
- **专业功能**：嵌入、重排序、翻译等

**维度分类逻辑说明：**
- **模态维度**：决定了模型核心处理能力和技术路线
- **规模维度**：决定了部署成本和设备适配范围
- **厂商维度**：体现了技术生态和路线差异
- **功能维度**：体现了具体应用价值和使用场景

### 2.3 大模型全面覆盖筛选策略
#### 2.3.1 多维度综合覆盖筛选
**筛选思路：**
1. **模态覆盖均衡**：确保纯文本、多模态、语音等不同处理模态的代表性覆盖
2. **规模分布连续**：从微型到超大规模的完整参数空间梯度覆盖
3. **厂商生态多样**：体现主要技术厂商的生态差异和发展路线

#### 2.3.2 10模型约束下的最优化
**优化目标：**
- 大模型关键特性维度最大化覆盖
- 模型数量控制在10个以下
- 体现端侧AI技术发展趋势
- 确保基准测试的代表性和指导性

#### 2.3.3 10模型选择权重策略
**维度权重设定原则：**
- 处理模态：35%（确保模态技术路线全面覆盖）
- 参数规模：35%（确保端侧设备适配覆盖）
- 厂商生态：30%（体现技术生态多样性）

### 2.4 测试工具
- **主要工具：** MNN_LLM_Benchmark框架
- **分析方法：** 大模型维度分析+全面覆盖筛选+多目标优化
- **数据来源：** MNN官方大模型库、社区活跃度统计、端侧应用数据分析

### 2.5 评估标准
**覆盖度标准：**
- 处理模态维度覆盖度 = 100%（文本、多模态、语音等模态全覆盖）
- 参数规模维度覆盖度 > 80%（从微型到中型梯度覆盖）
- 厂商生态维度覆盖度 > 80%（主要技术厂商生态覆盖）

**效率标准：**
- 选定模型数量控制在10个以下，确保代表性
- 总测试时间支持深度验证和多配置测试
- 关键技术特性和应用场景的高覆盖度

**实用性标准：**
- 选定模型在社区活跃度高
- 模型质量和稳定性经过验证
- 适配主流端侧设备

### 2.6 实施方式
**数据收集：**
- MNN模型库完整清单和特性标签
- 各模型的技术文档和性能数据
- 社区使用统计和趋势分析

**分析流程：**
1. 维度体系构建和权重设定
2. 模型特性标注和数据清洗
3. 覆盖度算法执行和优化
4. 结果验证和调整
5. 最终模型集确定

## 三、论证过程
### 3.1 执行步骤（基于大模型全生态）
1. **全面模型分析：** 分析150+模型的架构、规模、场景分布特性
2. **多维特性标注：** 为每个模型标注完整的维度特性信息
3. **覆盖度优化计算：** 在10个模型约束下实现最大维度覆盖
4. **最终模型集确定：** 输出10个以下具有全面代表性模型

### 3.2 测试环境
- **硬件：** FT D3000处理器（8核），32GB内存
- **软件：** MNN推理引擎（版本待定）
- **数据源：** MNN官方模型库、GitHub统计、社区数据
- **分析工具：** Python数据分析、覆盖度算法
- **备注：** 详细软硬件环境待细化为真实场景数据

### 3.3 基于全生态数据的预期结果
**预期选定模型数量：** 10个以下（从大模型全生态中精选）

**扩大候选模型范围：**
基于支撑文件中的MNN模型列表，按多维度分类得到的代表性候选：
- **纯文本代表：** Qwen2.5-0.5B、Hunyuan-1.8B、Meta-Llama-3.1-8B、Gemma-2-9b
- **多模态代表：** Qwen-VL-8B、Gemma-3-4b-it、MiniCPM-V-4、InternVL2_5-1B
- **专业功能代表：** Qwen2.5-Coder-7B、Qwen2.5-Math-7B、Qwen3-Embedding-8B
- **创新架构代表：** Qwen3-Thinking-4B、Qwen3-30B-A3B（MoE架构）
- **音频处理代表：** bert-vits2-MNN、piper-voices-MNN
- **专业领域代表：** Lingshu-7B（医疗）、DeepSeek-Prover-V2-7B（数学证明）

**覆盖度目标优化：**
| 维度 | 目标覆盖度 | 关键覆盖点 | 实现方式 |
|------|------------|------------|----------|
| 处理模态 | 100% | 纯文本、多模态端到端覆盖 | 4+4模型组合 |
| 参数规模 | >80% | 微型-小型-中型覆盖 | 0.5B-10B |
| 厂商生态 | >80% | Qwen、Meta、Google、Apple、HuggingFace、国产厂商 | 3+1+1+1+1+2模型分布 |
**备注：**
- Embedding / Reranker 模型因为不会有token生成，不适用于MNN LLM Benchmark工具进行测试
- 语音模型数量较少，且只支持单种语言（英语或者中文），测试意义不大
- 代码、数学、医学等应用功能，样本量较少，可比性不大

**预期效率提升：**
- 模型数量精简到最小可行集
- 测试时间大幅减少，支持深度验证
- LLM关键特性100%覆盖，确保基准测试完整性

### 3.4 关键分析重点（全面覆盖策略）
**代表性验证：**
- 选定模型是否能代表MNN大模型生态的全貌和技术趋势
- 是否体现AI技术从单一模态向多模态发展的演进
- 选定模型在端侧实际应用中的典型性和指导性

**实用性验证：**
- 选定模型在端侧设备上的实际性能和适配性
- 【等待各模型社区活跃度和部署数据补充】
- 模型在不同应用场景下的实用价值和效果

**全面性评估：**
- 多模态模型的主流化趋势是否得到充分体现
- 从微型到超大规模的模型适配覆盖是否合理
- 不同技术路线和应用领域的影响力和发展潜力

## 四、论证结论及最终选定
### 4.1 基于全生态的分析结论
**核心发现：**
- MNN的150+模型库展现了**大模型技术的多元化发展趋势**
- **架构相对统一**：大部分模型基于Transformer架构及其变体，差异主要体现在模态、规模、任务专用性
- 在10个模型约束下，可以实现**关键维度的高覆盖度代表性建摸**

**筛选策略合理性：**
- 10个模型选择**在可行性和代表性之间达到最佳平衡**
- 充分反映大模型技术从单一文本到多模态应用的**技术演进趋势**
- 为端侧基准测试建立**全面性、前瞻性的技术评估标准**

### 4.2 推荐的最终模型选定列表
**基于多维度覆盖分析和实用价值评估，推荐以下10个模型的最终选定集：**

| 序号 | 模型名称                         | 参量规模 | 主要模态 | 应用场景 | 技术特性 | 选中理由                          |
|------|------------------------------|----------|----------|----------|----------|-------------------------------|
| 1 | Qwen2.5-0.5B-Instruct        | 0.5B | 纯文本 | 通用对话 | 基础处理 | 微型级文本代表，轻量部署                  |
| 2 | Hunyuan-1.8B-Instruct        | 1.8B | 纯文本 | 通用对话 | 256k长上下文 | 小型级中端代表，长上下文能力                |
| 3 | Qwen3-4B-Thinking-2507       | 4B | 纯文本 | 通用对话 | 256k长上下文 | 中型级主流文本代表                     |
| 4 | Meta-Llama-3.1-8B-Instruct   | 8B | 纯文本 | 通用对话 | 国际标准 | 大型级国际标准代表                     |
| 5 | FastVLM-0.5B-Stage3          | 0.5B | 图文理解 | 视觉理解 | 高效视觉编码 | 轻量多模态领域代表，处理高分辨率图像能力          |
| 6 | SmolVLM2-500M-Video-Instruct | 0.5B | 多模态 | 视频理解 | 分析视频内容 | 轻量多模态代表，支持视频图像输入              |
| 7 | gemma-3-4b-it-q4_0           | 4B | 多模态 | 视觉理解 | 高效处理 | 中型级多模态代表，支持视觉理解能力及140多种语言     |
| 8 | deepseek-vl-7b-chat          | 7B | 多模态 | 视觉理解 | 视觉编码器 | 中型级多模态代表，支持高分辨率图像             |
| 9 | Qwen2.5-Omni-7B              | 7B | 多模态 | 视觉语音文本 | Thinker-Talker架构 | 中型级多模态代表，支持文本、图像、音频和视频在内的多种模态 |

**覆盖度分析：**
- **参数规模覆盖**：0.5B、1.8B、4B、7B、8B梯度覆盖
- **处理模态覆盖**：纯文本(50%)、多模态(50%)平衡分布
- **厂商生态覆盖**：通义千问(30%)、Meta(10%)、Google(10%)、Apple(10%)、HuggingFace(10%)、国产厂商(20%)多样覆盖

**最终决策建议：**
建议采用10个模型的完整方案，确保全面的维度覆盖。基于端侧AI发展的多元化和专业化趋势，完整的10模型集合能够为基准测试提供最全面的评估基准。


## 附录

### A.1 大模型全生态可用清单（基于MNN官方数据）
**主要厂商及技术路线：**
- **通义千问系列**：Qwen2.5/3（文本）、Qwen-VL（多模态）、Qwen2.5-Coder（代码）、Qwen2.5-Math（数学）
- **Meta Llama系列**：Llama-3.1（文本）、【多模态版本待确认】
- **Google Gemma系列**：Gemma-2/3（多模态兼备），覆盖1B-9B范围
- **腾讯混元系列**：Hunyuan（文本、代码），支持长上下文256k
- **专业厂商**：DeepSeek（数学推理）、MiniCPM（视觉）、InternVL（文档理解）、Lingshu（医疗）等

**完整架构分布：**
- **文本处理架构**：【占比待统计】- 标准Transformer及优化变体
- **多模态架构**：【占比待统计】- 视觉-语言融合架构
- **语音处理架构**：【占比待统计】- 语音合成和识别专用架构
- **创新架构模式**：Thinking模式、MoE架构混合专家等

**全规模覆盖分布：**
- 微型(<1B)：Qwen2.5-0.5B、MobileLLM-125M-600M、SmolLM2-256M等
- 小型(1-2B)：Hunyuan-1.8B、Qwen-VL-2B、Gemma-3-270M等
- 中型(3-8B)：Qwen3-4B、Meta-Llama-3.1-8B、MiniCPM-V-4、InternVL2_5-1B等
- 大型(8-10B)：Qwen-VL-8B、Gemma-2-9B等
- 超大型(MoE)：Qwen3-30B-A3B、Qwen-VL-30B-A3B（总参数30B+，Active参数3-4B）

### A.2 多目标覆盖度计算方法
**单维度覆盖度定义：**
```
维度覆盖度 = (选定模型覆盖的维度特征数 / 维度总特征数) × 100%
```

**综合覆盖度计算：**
```
综合覆盖度 = Σ(维度覆盖度 × 维度权重)
```

**多目标优化函数：**
```
Maximize: α×架构覆盖度 + β×规模覆盖度 + γ×场景覆盖度 + δ×特性覆盖度
Subject to: 模型数量 ≤ 10, 架构≥90%, 规模=100%, 场景≥95%, 特性≥85%
```
其中 α=0.30, β=0.25, γ=0.35, δ=0.10 为权重系数

### A.3 实施工具
**数据分析工具：** Python pandas、numpy
**算法实现：** 覆盖度优化算法、贪心选择
**可视化：** 维度覆盖热力图、模型分布图

---

**文档版本**: v1.0  
**最后更新**: 2025年11月19日  
**维护责任**: EAO基准测试项目团队