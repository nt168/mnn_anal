## 轻量级（2B以下）：

- Qwen2.5-0.5B-Instruct-MNN（Qwen）: 遵循指令，可以生成长文本，对于理解结构化数据以及生成结构化输出有明显提升。
- Hunyuan-1.8B-Instruct-MNN（腾讯混元）: 支持快速与慢速思考模式，使用者灵活选择。支持超长上下文（256k）。
- FastVLM-0.5B-Stage3-MNN（Apple）：具有高效视觉编码， 提升模型的处理速度和性能， 尤其是高分辨率图像，减少编码时间和token数量。
- SmolVLM2-500M-Video-Instruct-MNN（HuggingFace）：专注于视觉语言任务，可处理视频、图像和文本输入，生成文本输出。体积小，内存效率高。

## 中量级：

- Qwen3-4B-Thinking-2507-MNN（Qwen）：支持更长上下文（256k），在逻辑推理，代码，数学等领域性能显著增强，在指令跟随，工具使用等通用能力上也有明显改进。
- Meta-Llama-3.1-8B-Instruct-MNN（Meta）：使用监督调优和有人类反馈的强化学习来与人类便好一致。评测结果在MMLU、GPQA、HumanEval等多项基准上胜过Gemma 7B和Mistral 7B Instruct等同级模型。
- gemma-3-4b-it-q4_0-mnn（Google）： 支持文字和图片输入并生成文字。支持140多种语言，适用于文本生成和图片理解等任务， 在性能，速度，和资源消耗间取得平衡。
- deepseek-vl-7b-chat-MNN（DeepSeek）：使用视觉编码器，支持高分辨率图片输入。在多模态理解能力评测数据集上取得了领先的成绩。
- Qwen2.5-Omni-7B (Qwen) : 使用Thinker-Talker架构，支持包括文本、图像、音频和视频在内的多种模态，同时以流式方式生成文本和自然语音响应。
